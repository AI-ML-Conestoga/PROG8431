{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad439c69",
   "metadata": {},
   "source": [
    "# Problem Analysis – Workshop 1\n",
    "\n",
    "#### Group 4 – Team Members\n",
    "\n",
    "- **Manu Mathew** – 8990691  \n",
    "- **Yogesh Kumar Gopal** – 8996403  \n",
    "- **Jahnavi Pakanati** – 9013742  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a434afd7",
   "metadata": {},
   "source": [
    "#### Setup and configuration steps necessary to run the code that follows in later cells.\n",
    "\n",
    "##### Project Layout\n",
    "- `csv/` - Folder to store the processed .csv file which is generated using the .data file\n",
    "- `data/` - Folder to store the original dataset.\n",
    "- `problemanalysisenv/` - Manages the project specific dependencies without affecting the global Python installations.\n",
    "- `problemAnalysisWorkshop1.ipynb` - This is the Jupyter notebook file which will have the code to read and clean the data for this assignment.\n",
    "- `requirements.txt` - This file lists all the Python packages to run the notebook.\n",
    "\n",
    "##### Configuration steps required to run the code\n",
    "- Download the project `Problem Analysis  Workshop 1`.\n",
    "- Open bash in terminal in vscode.\n",
    "- And then in the terminal , execute the following\n",
    "```bash\n",
    "        cd Problem\\ Analysis\\ \\ Workshop\\ 1/\n",
    "```\n",
    "- Then create a virtual environment using the command\n",
    "```python\n",
    "    py -m venv \"problemanalysisenv\"\n",
    "```\n",
    "\n",
    "- Now, activate the virtual environment, using the following command shown below:\n",
    "```bash\n",
    "    source ./problemanalysisenv/Scripts/activate\n",
    "```\n",
    "\n",
    "- Now, install the dependencues mentioned in the requirements.txt using the command shown below:\n",
    "```bash\n",
    "    pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "- Now that our environment is setup, we can create the jupyter notebooks to implement and execute the code to clean the dataset. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8bb4ec",
   "metadata": {},
   "source": [
    "##### Problem description\n",
    "\n",
    "This project looks at census income data to better understand what factors might affect a person’s income. It involves cleaning and organizing the dataset based on the different steps outlined below.\n",
    "\n",
    "- Link to dataset : <ins>https://archive.ics.uci.edu/dataset/2/adult</ins>\n",
    "\n",
    "##### Steps required to clean the income dataset\n",
    "- Import the required libraries and for the current dataset we are using `pandas`.\n",
    "- Delcare the global variables on the top based on good programming practice.\n",
    "- Read the dataset and incase, if column or feature are not there in the dataset, then add the required columns and form a .csv file out of  .\n",
    "- Identify the columns that does not provide any information relavant to the problem statement and drop those columns\n",
    "- Identify the columns that have some logical relationship with one another, group them accordingly and restructure the dataset to confirm the third normal form (3NF) by mapping this groups back to original data.\n",
    "- Delete the columns once mapped with the original data and also these groups that were excluded as a part of 3NF can be converted .csv files for reference.\n",
    "- Find the inconsistent entries, empty spaces , NULL and NaN values and convert them to a standard missing value like \"NaN\" to ensure consistency in handling the data.\n",
    "- Once the above steps are done, we can convert the final cleaned dataset into .csv file for data analysis.\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1339d19",
   "metadata": {},
   "source": [
    "##### Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d92ac0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b441f5c",
   "metadata": {},
   "source": [
    "##### Read the adult.data file and add column names to that based on adult.names and convert the dataframe to .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f7677088",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/adult.data', header=None)\n",
    "df.columns = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\",\"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\",\"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"]\n",
    "df.to_csv('./csv/temp_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8b3acf",
   "metadata": {},
   "source": [
    "##### Drop the fnlwgt column as this column does not provide information relevant to problem statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9f0195db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"fnlwgt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdfe8fe",
   "metadata": {},
   "source": [
    "##### Columns education and education-num are related to each other, so we create a seperate table for the same and convert into .csv file for future reference and then map their Id to the original data and also drop education and education-num from original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "62c42d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "education_map = df[[\"education\", \"education-num\"]].drop_duplicates().reset_index(drop=True)\n",
    "education_map[\"education_id\"] = education_map.index + 1\n",
    "education_map.to_csv(\"./csv/education.csv\", index=False)\n",
    "\n",
    "df = df.merge(education_map, on=[\"education\", \"education-num\"], how=\"left\")\n",
    "df = df.drop(columns=[\"education\", \"education-num\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c154a6d6",
   "metadata": {},
   "source": [
    "##### Create a seperate table for marital-status, occupation and also convert them to seperate .csv files and map their Id's to original data and also drop these columns from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b64843f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "marital_status_map = df[[\"marital-status\"]].drop_duplicates().reset_index(drop=True)\n",
    "marital_status_map[\"marital_status_id\"] = marital_status_map.index + 1\n",
    "marital_status_map.to_csv(\"./csv/marital.csv\", index=False)\n",
    "\n",
    "df = df.merge(marital_status_map, on=[\"marital-status\"] ,how=\"left\")\n",
    "df = df.drop(columns=[\"marital-status\"])\n",
    "\n",
    "occupation_map = df[[\"occupation\"]].drop_duplicates().reset_index(drop=True)\n",
    "occupation_map[\"occupation_id\"] = occupation_map.index + 1\n",
    "occupation_map.to_csv(\"./csv/occupation.csv\", index=False)\n",
    "\n",
    "df = df.merge(occupation_map, on=[\"occupation\"] ,how=\"left\")\n",
    "df = df.drop(columns=[\"occupation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe6cd71",
   "metadata": {},
   "source": [
    "##### Find the inconsistent entries like the empty space, Null , ? and NaN and convert them to \"NaN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "235973ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(lambda col: col.map(lambda x: \"nan\" if str(x).strip() == '?' else x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfd9c89",
   "metadata": {},
   "source": [
    "##### Convert the final dataframe into the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "65a15a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.to_csv(\"./csv/final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1cafda",
   "metadata": {},
   "source": [
    "##### References\n",
    "- 1. https://archive.ics.uci.edu/dataset/2/adult"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "problemanalysisenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
